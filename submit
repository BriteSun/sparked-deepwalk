#!/bin/bash

if [ $# -eq 0 ] 
then
  echo "Usage: submit dataset_name"
  exit 1
fi

SAVE_PATH="/tmp/"
NO_OF_RANDOM_WALKS=80
RANDOM_WALK_LENGTH=40
VECTOR_DIM=128
NUM_PARTITIONS=1
NUM_ITERATIONS=1
WINDOW_SIZE=10

DATASET=$1

DATASET_NAME=$DATASET
DATASET_ROOT="datasets/$DATASET/data/"
EDGES_FILE="edges.csv"
NODES_FILE="nodes.csv"
LABELS_FILE="groups.csv"
NODE_TAG_FILE="group-edges.csv" 

time spark-submit --master spark://10.6.15.148:7077  \
                  --jars lib/Graphviz4S-1.0-SNAPSHOT.jar \
                  --class com.nrl.SparkedDeepWalkApp \
                  --conf spark.driver.memory=6g \
                  --conf spark.executor.memory=6g \
                  --conf spark.driver.maxResultSize=7g \
                  target/scala-2.11/sparked-deepwalk_2.11-1.0.jar \
                  $DATASET_NAME \
                  $DATASET_ROOT \
                  $NODES_FILE \
                  $EDGES_FILE \
                  $LABELS_FILE \
                  $NODE_TAG_FILE \
                  $SAVE_PATH \
                  $RANDOM_WALK_LENGTH \
                  $NO_OF_RANDOM_WALKS \
                  $VECTOR_DIM \
                  $NUM_PARTITIONS \
                  $NUM_ITERATIONS \
                  $WINDOW_SIZE 

OUTPUT_SUFFIX="_vertex_visit_freq.csv"
#python utils/plot.py $SAVE_PATH$DATASET_NAME$OUTPUT_SUFFIX $DATASET_NAME 

VEC_SUFFIX="_vec.txt"
#python utils/scoring.py --emb $SAVE_PATH$DATASET_NAME$VEC_SUFFIX --edgelist datasets/$DATASET_NAME/data/edges.csv --labellist datasets/$DATASET_NAME/data/group-edges.csv --small
